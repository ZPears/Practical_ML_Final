---
title: "PRACTICAL MACHINE LEARNING FINAL PROJECT"
output: html_document
---

### Introduction

```{r echo=FALSE, warning=FALSE}
  library(caret)
  training <- read.csv('pml-training.csv')
  testing <- read.csv('pml-testing.csv')
```

This project will detail the construction of a model to predict the type of exercise a person performed based on the data provided [at this link](http://groupware.les.inf.puc-rio.br/har). The exercises are all different dumbell movements, classified as "A", "B", "C", "D" and "E" in the data set "classe" variable.


```{r}
  summary(training$classe)
```

The report will cover the following:

* Model Construction
* Cross Validation
* Expected Out of Sample Error

First, we will remove near zero variance predictors from the potential set of predictors, so that our eventual models are more robust. The testing set is cleaned as well.


```{r}
  nearZero <- nearZeroVar(training)
  training <- training[, -nearZero]
  testing <- testing[, -nearZero]
```

To make a 5-fold cross validation - which gives us an 80-20 split for each validation set - some parameters are passed to trainControl:

```{r}
  ctrl <- trainControl(method='repeatedcv', number=5)
```

To begin, a random forest model is fit. This type of model is tried first because Professor Leek mentioned that is it often the best performing (though also computationally expensive).

```{r warnings=FALSE, message=FALSE}
  rfModel <- train(classe ~ ., data=training, method='rf', trControl=ctrl)
```

Peformance check:

```{r echo=FALSE}
  rfModel$finalModel
```

Classification error is quite low - estimated out of sample error rate should be approximately 0.49%, as out-of-bag error estimate is roughly approximate.